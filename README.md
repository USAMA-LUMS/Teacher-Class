# Teacher-Class Network: A Neural Network Compression Mechanism
A sample implementation of the teacher-class network. The proposed architecture has two key differences when compared to existing teacher-student approaches, (i)instead of just one student, the proposed architecture employs multiple students to learn mutually exclusive chunks of the knowledge and (ii) instead of training students on the soft labels of the teacher, this architecture tries to learn dense feature representations, thus making the solution problem independent. The size of chunk each student has to learn depends on the number of students. After all of the students have been trained independently, the knowledge learned by each individual student is combined and output layers are applied. These layers can be borrowed from teacher network with pre-trained weights and can also be fine-tuned to further improve the loss occurred while transferring the knowledge to students.
